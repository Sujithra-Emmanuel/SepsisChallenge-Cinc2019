{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author : Ines Krissaane "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import glob\n",
    "from sklearn import linear_model\n",
    "import datetime\n",
    "from sklearn.preprocessing import  StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "from random import sample \n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and pre-processing (cf 1.Pre-processing.ipynb and 2.RandomForest.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1552210, 44)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr = pd.read_csv('sepsis_data_all.csv')\n",
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove variables with more than 82% of na.\n",
    "X_tr.drop(['EtCO2', 'BaseExcess','HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN', 'Alkalinephos',\n",
    "    'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct' ,'Lactate','Magnesium','Phosphate',\n",
    "    'Potassium', 'Bilirubin_total', 'TroponinI','Hct', 'Hgb','PTT',  'WBC', 'Unnamed: 0','Fibrinogen', 'Platelets',\n",
    "    \"Glucose\", 'Unit1', \"Unit2\", \"HospAdmTime\",'X', 'DBP', 'SBP', 'O2Sat','ID'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr.fillna(method='bfill', inplace=True)\n",
    "X_tr.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr['RE'] = pd.read_csv('REfromAENN.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR</th>\n",
       "      <th>Temp</th>\n",
       "      <th>MAP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ICULOS</th>\n",
       "      <th>SepsisLabel</th>\n",
       "      <th>RE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.0</td>\n",
       "      <td>36.11</td>\n",
       "      <td>75.33</td>\n",
       "      <td>19.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3356.875619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97.0</td>\n",
       "      <td>36.11</td>\n",
       "      <td>75.33</td>\n",
       "      <td>19.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3357.300234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.0</td>\n",
       "      <td>36.11</td>\n",
       "      <td>86.00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3408.611028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.0</td>\n",
       "      <td>36.11</td>\n",
       "      <td>91.33</td>\n",
       "      <td>30.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3628.793299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103.0</td>\n",
       "      <td>36.11</td>\n",
       "      <td>91.33</td>\n",
       "      <td>24.5</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3944.002592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      HR   Temp    MAP  Resp    Age  Gender  ICULOS  SepsisLabel           RE\n",
       "0   97.0  36.11  75.33  19.0  83.14       0       1            0  3356.875619\n",
       "1   97.0  36.11  75.33  19.0  83.14       0       2            0  3357.300234\n",
       "2   89.0  36.11  86.00  22.0  83.14       0       3            0  3408.611028\n",
       "3   90.0  36.11  91.33  30.0  83.14       0       4            0  3628.793299\n",
       "4  103.0  36.11  91.33  24.5  83.14       0       5            0  3944.002592"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tr = X_tr.SepsisLabel\n",
    "X_tr.drop(['SepsisLabel'], axis = 1, inplace = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tr,Y_tr,test_size=.3, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (1086547, 8)\n",
      "Training Labels Shape: (1086547,)\n",
      "Testing Features Shape: (465663, 8)\n",
      "Testing Labels Shape: (465663,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', X_train.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Features Shape:', X_test.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation(clfs):\n",
    "    for clf in clfs:\n",
    "        clfs[clf]['score'] = cross_val_score(clfs[clf]['clf'], data,Y_tr, cv=5,scoring='roc_auc')\n",
    "        print(clfs[clf]['name'] + \": %0.4f (+/- %0.4f)\" % (clfs[clf]['score'].mean(), clfs[clf]['score'].std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 0.7071 (+/- 0.0127)\n",
      "AdaBoostClassifier: 0.7624 (+/- 0.0145)\n",
      "GradientBoostingClassifier: 0.7673 (+/- 0.0159)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest: 0.6252 (+/- 0.0095)\n",
      "DecisionTreeClassifier: 0.5295 (+/- 0.0068)\n",
      "KNeighborsClassifier: 0.5584 (+/- 0.0066)\n"
     ]
    }
   ],
   "source": [
    "clfs = {}\n",
    "\n",
    "clfs['reg'] = {'clf': LogisticRegression(), 'name': 'LogisticRegression'}\n",
    "clfs['ada'] = {'clf': AdaBoostClassifier(), 'name': 'AdaBoostClassifier'}\n",
    "clfs['gbc'] = {'clf': GradientBoostingClassifier(), 'name': 'GradientBoostingClassifier'}\n",
    "clfs['rf'] = {'clf': RandomForestClassifier( n_jobs=-1), 'name':'RandomForest'}\n",
    "clfs['tree'] = {'clf': DecisionTreeClassifier(), 'name':'DecisionTreeClassifier'}\n",
    "clfs['knn'] = {'clf': KNeighborsClassifier(), 'name': 'KNeighborsClassifier'}\n",
    "\n",
    "\n",
    "Evaluation(clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auc(labels, predictions):\n",
    "    # Check inputs for errors.\n",
    "\n",
    "    # Find prediction thresholds.\n",
    "    thresholds = np.unique(predictions)[::-1]\n",
    "    if thresholds[0] != 1:\n",
    "        thresholds = np.concatenate((np.array([1]), thresholds))\n",
    "\n",
    "    if thresholds[-1] != 0:\n",
    "        thresholds = np.concatenate((thresholds, np.array([0])))\n",
    "    m = len(thresholds)\n",
    "\n",
    "    # Populate contingency table across prediction thresholds.\n",
    "    tp = np.zeros(m)\n",
    "    fp = np.zeros(m)\n",
    "    fn = np.zeros(m)\n",
    "    tn = np.zeros(m)\n",
    "\n",
    "    # Find indices that sort predicted probabilities from largest to smallest.\n",
    "    idx = np.argsort(predictions)[::-1]\n",
    "\n",
    "    i = 0\n",
    "    for j in range(m):\n",
    "        # Initialize contingency table for j-th prediction threshold.\n",
    "        if j == 0:\n",
    "            tp[j] = 0\n",
    "            fp[j] = 0\n",
    "            fn[j] = np.sum(labels == 1)\n",
    "            tn[j] = np.sum(labels == 0)\n",
    "        else:\n",
    "            tp[j] = tp[j - 1]\n",
    "            fp[j] = fp[j - 1]\n",
    "            fn[j] = fn[j - 1]\n",
    "            tn[j] = tn[j - 1]\n",
    "\n",
    "        # Update contingency table for i-th largest prediction probability.\n",
    "        while i < n and predictions[idx[i]] >= thresholds[j]:\n",
    "            if labels[idx[i]]:\n",
    "                tp[j] += 1\n",
    "                fn[j] -= 1\n",
    "            else:\n",
    "                fp[j] += 1\n",
    "                tn[j] -= 1\n",
    "            i += 1\n",
    "\n",
    "    # Summarize contingency table.\n",
    "    tpr = np.zeros(m)\n",
    "    tnr = np.zeros(m)\n",
    "    ppv = np.zeros(m)\n",
    "    npv = np.zeros(m)\n",
    "\n",
    "    for j in range(m):\n",
    "        if tp[j] + fn[j]:\n",
    "            tpr[j] = tp[j] / (tp[j] + fn[j])\n",
    "        else:\n",
    "            tpr[j] = 1\n",
    "        if fp[j] + tn[j]:\n",
    "            tnr[j] = tn[j] / (fp[j] + tn[j])\n",
    "        else:\n",
    "            tnr[j] = 1\n",
    "        if tp[j] + fp[j]:\n",
    "            ppv[j] = tp[j] / (tp[j] + fp[j])\n",
    "        else:\n",
    "            ppv[j] = 1\n",
    "        if fn[j] + tn[j]:\n",
    "            npv[j] = tn[j] / (fn[j] + tn[j])\n",
    "        else:\n",
    "            npv[j] = 1\n",
    "\n",
    "    # Compute AUROC as the area under a piecewise linear function of TPR /\n",
    "    # sensitivity (x-axis) and TNR / specificity (y-axis) and AUPRC as the area\n",
    "    # under a piecewise constant of TPR / recall (x-axis) and PPV / precision\n",
    "    # (y-axis).\n",
    "    auroc = 0\n",
    "    auprc = 0\n",
    "    for j in range(m-1):\n",
    "        auroc += 0.5 * (tpr[j + 1] - tpr[j]) * (tnr[j + 1] + tnr[j])\n",
    "        auprc += (tpr[j + 1] - tpr[j]) * ppv[j + 1]\n",
    "\n",
    "    return auroc, auprc\n",
    "\n",
    "# The compute_accuracy_f_measure function computes the accuracy and F-measure\n",
    "# for a patient.\n",
    "#\n",
    "# Inputs:\n",
    "#   'labels' is a binary vector, where labels[i] == 0 if the patient is not\n",
    "#   labeled as septic at time i and labels[i] == 1 if the patient is labeled as\n",
    "#   septic at time i.\n",
    "#\n",
    "#   'predictions' is a binary vector, where predictions[i] == 0 if the patient\n",
    "#   is not predicted to be septic at time i and predictions[i] == 1 if the\n",
    "#   patient is predicted to be septic at time i.  Note that there must be a\n",
    "#   prediction for every label, i.e, len(labels) == len(predictions).\n",
    "#\n",
    "# Output:\n",
    "#   'accuracy' is a scalar that gives the accuracy of the classifier using its\n",
    "#   binarized predictions.\n",
    "#\n",
    "#   'f_measure' is a scalar that gives the F-measure of the classifier using its\n",
    "#   binarized predictions.\n",
    "#\n",
    "# Example:\n",
    "#   In [1]: labels = [0, 0, 0, 0, 1, 1]\n",
    "#   In [2]: predictions = [0, 0, 1, 1, 1, 1]\n",
    "#   In [3]: accuracy, f_measure = compute_prediction_utility(labels, predictions)\n",
    "#   In [4]: accuracy\n",
    "#   Out[4]: 0.666666666667\n",
    "#   In [5]: f_measure\n",
    "#   Out[5]: 0.666666666667\n",
    "\n",
    "def compute_accuracy_f_measure(labels, predictions):\n",
    "    # Check inputs for errors.\n",
    "    if len(predictions) != len(labels):\n",
    "        raise Exception('Numbers of predictions and labels must be the same.')\n",
    "\n",
    "    n = len(labels)\n",
    "    for i in range(n):\n",
    "        if not labels[i] in (0, 1):\n",
    "            raise Exception('Labels must satisfy label == 0 or label == 1.')\n",
    "\n",
    "    for i in range(n):\n",
    "        if not predictions[i] in (0, 1):\n",
    "            raise Exception('Predictions must satisfy prediction == 0 or prediction == 1.')\n",
    "\n",
    "    # Populate contingency table.\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        if labels[i] and predictions[i]:\n",
    "            tp += 1\n",
    "        elif labels[i] and not predictions[i]:\n",
    "            fp += 1\n",
    "        elif not labels[i] and predictions[i]:\n",
    "            fn += 1\n",
    "        elif not labels[i] and not predictions[i]:\n",
    "            tn += 1\n",
    "\n",
    "    # Summarize contingency table.\n",
    "    if tp + fp + fn + tn:\n",
    "        accuracy = float(tp + tn) / float(tp + fp + fn + tn)\n",
    "    else:\n",
    "        accuracy = 1.0\n",
    "\n",
    "    if 2 * tp + fp + fn:\n",
    "        f_measure = float(2 * tp) / float(2 * tp + fp + fn)\n",
    "    else:\n",
    "        f_measure = 1.0\n",
    "\n",
    "    return accuracy, f_measure\n",
    "\n",
    "# The compute_prediction_utility function computes the total time-dependent\n",
    "# utility for a patient.\n",
    "#\n",
    "# Inputs:\n",
    "#   'labels' is a binary vector, where labels[i] == 0 if the patient is not\n",
    "#   labeled as septic at time i and labels[i] == 1 if the patient is labeled as\n",
    "#   septic at time i.\n",
    "#\n",
    "#   'predictions' is a binary vector, where predictions[i] == 0 if the patient\n",
    "#   is not predicted to be septic at time i and predictions[i] == 1 if the\n",
    "#   patient is predicted to be septic at time i.  Note that there must be a\n",
    "#   prediction for every label, i.e, len(labels) == len(predictions).\n",
    "#\n",
    "# Output:\n",
    "#   'utility' is a scalar that gives the total time-dependent utility of the\n",
    "#   classifier using its binarized predictions.\n",
    "#\n",
    "# Example:\n",
    "#   In [1]: labels = [0 0 0 0 1 1]\n",
    "#   In [2]: predictions = [0 0 1 1 1 1]\n",
    "#   In [3]: utility = compute_prediction_utility(labels, predictions)\n",
    "#   In [4]: utility\n",
    "#   Out[4]: 0.444444444444\n",
    "\n",
    "def compute_prediction_utility(labels, predictions, dt_early=-12, dt_optimal=-6, dt_late=3.0, max_u_tp=1, min_u_fn=-2, u_fp=-0.05, u_tn=0):\n",
    "    # Check inputs for errors.\n",
    "    if len(predictions) != len(labels):\n",
    "        raise Exception('Numbers of predictions and labels must be the same.')\n",
    "\n",
    "    n = len(labels)\n",
    "    for i in range(n):\n",
    "        if not labels[i] in (0, 1):\n",
    "            raise Exception('Labels must satisfy label == 0 or label == 1.')\n",
    "\n",
    "    for i in range(n):\n",
    "        if not predictions[i] in (0, 1):\n",
    "            raise Exception('Predictions must satisfy prediction == 0 or prediction == 1.')\n",
    "\n",
    "    if dt_early >= dt_optimal:\n",
    "        raise Exception('The earliest beneficial time for predictions must be before the optimal time.')\n",
    "\n",
    "    if dt_optimal >= dt_late:\n",
    "        raise Exception('The optimal time for predictions must be before the latest beneficial time.')\n",
    "\n",
    "    # Does the patient eventually have sepsis?\n",
    "    if any(labels):\n",
    "        is_septic = True\n",
    "        t_sepsis = min(i for i, label in enumerate(labels) if label) - dt_optimal\n",
    "    else:\n",
    "        is_septic = False\n",
    "        t_sepsis = float('inf')\n",
    "\n",
    "    # Define slopes and intercept points for affine utility functions of the\n",
    "    # form u = m * t + b.\n",
    "    m_1 = float(max_u_tp) / float(dt_optimal - dt_early)\n",
    "    b_1 = -m_1 * dt_early\n",
    "    m_2 = float(-max_u_tp) / float(dt_late - dt_optimal)\n",
    "    b_2 = -m_2 * dt_late\n",
    "    m_3 = float(min_u_fn) / float(dt_late - dt_optimal)\n",
    "    b_3 = -m_3 * dt_optimal\n",
    "\n",
    "    # Compare predicted and true conditions.\n",
    "    u = np.zeros(n)\n",
    "    for t in range(n):\n",
    "        if t <= t_sepsis + dt_late:\n",
    "            # TP\n",
    "            if is_septic and predictions[t]:\n",
    "                if t <= t_sepsis + dt_optimal:\n",
    "                    u[t] = max(m_1 * (t - t_sepsis) + b_1, u_fp)\n",
    "                elif t <= t_sepsis + dt_late:\n",
    "                    u[t] = m_2 * (t - t_sepsis) + b_2\n",
    "            # FN\n",
    "            elif is_septic and not predictions[t]:\n",
    "                if t <= t_sepsis + dt_optimal:\n",
    "                    u[t] = 0\n",
    "                elif t <= t_sepsis + dt_late:\n",
    "                    u[t] = m_3 * (t - t_sepsis) + b_3\n",
    "            # FP\n",
    "            elif not is_septic and predictions[t]:\n",
    "                u[t] = u_fp\n",
    "            # TN\n",
    "            elif not is_septic and not predictions[t]:\n",
    "                u[t] = u_tn\n",
    "\n",
    "    # Find total utility for patient.\n",
    "    return np.sum(u)\n",
    "\n",
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser(description = 'Evaluate classifiers for cohort.')\n",
    "    parser.add_argument('-l', '--labels_directory',      type=str, required=True,  help='Labels directory')\n",
    "    parser.add_argument('-p', '--predictions_directory', type=str, required=True,  help='Predictions directory')\n",
    "    parser.add_argument('-o', '--output_file',           type=str, required=False, help='Output filename')\n",
    "    return parser\n",
    "\n",
    "def run(args):\n",
    "    auroc, auprc, accuracy, f_measure, utility = compute_scores_2019(args.labels_directory, args.predictions_directory)\n",
    "\n",
    "    output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(auroc, auprc, accuracy, f_measure, utility)\n",
    "\n",
    "    if args.output_file:\n",
    "        with open(args.output_file, 'w') as f:\n",
    "            f.write(output_string)\n",
    "    else:\n",
    "        print(output_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = pd.read_csv('sepsis_data_all.csv')\n",
    "X_tr.drop(['EtCO2', 'BaseExcess','HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN', 'Alkalinephos',\n",
    "    'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct' ,'Lactate','Magnesium','Phosphate',\n",
    "    'Potassium', 'Bilirubin_total', 'TroponinI','Hct', 'Hgb','PTT',  'WBC', 'Unnamed: 0','Fibrinogen', 'Platelets',\n",
    "    \"Glucose\", 'Unit1', \"Unit2\", \"HospAdmTime\",'X', 'DBP', 'SBP', 'O2Sat','ID'], axis = 1, inplace = True)\n",
    "X_tr.fillna(method='bfill', inplace=True)\n",
    "X_tr.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr['RE'] = pd.read_csv('REfromAENN.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression 1 with Gender, SBP, DBP\n",
    "Y_tr = X_tr.SepsisLabel\n",
    "X_tr.drop(['SepsisLabel'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tr,Y_tr,test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals import joblib\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                       multi_class='multinomial').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01784122852792685"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((clf.predict(X_test) - y_test)**2 )/len(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9821587714720732"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'regression_model7.sav'\n",
    "joblib.dump(clf, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code(file) :\n",
    "    data = pd.read_csv(file , sep='|')\n",
    "    data.drop(['EtCO2', 'BaseExcess','HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN', 'Alkalinephos',\n",
    "    'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct' , 'Lactate','Magnesium','Phosphate',\n",
    "    'Potassium', 'Bilirubin_total', 'TroponinI','Hct', 'Hgb','PTT',  'WBC', 'Fibrinogen', 'Platelets',\n",
    "    \"Unit1\", 'Unit2', \"Glucose\", \"HospAdmTime\", 'SBP', 'DBP', 'O2Sat'], axis = 1, inplace = True)\n",
    "    data.fillna(method='bfill', inplace=True)\n",
    "    data.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    Y_te = data.SepsisLabel\n",
    "    data.drop(['SepsisLabel'], axis = 1, inplace = True)\n",
    "    col = data.columns\n",
    "    if sum(pd.isna(data['MAP'])) !=0 : \n",
    "        data['MAP'] =  [87] * len(data['MAP'] )\n",
    "    if sum(pd.isna(data['Temp'])) !=0 : \n",
    "        data['Temp'] =  [36.7] * len(data['Temp'] )\n",
    "    if sum(pd.isna(data['HR'])) !=0 : \n",
    "        data['HR'] =  [83.9] * len(data['HR'] )\n",
    "    if sum(pd.isna(data['Resp'])) !=0  :\n",
    "        data['Resp'] =  [19.5] * len(data['Resp'] )\n",
    "        \n",
    "    variables = ['Resp','MAP','Temp','HR']\n",
    "    for var in variables :\n",
    "        l2 = []\n",
    "        l2.append(list(data[var] - data[var].mean()))\n",
    "        data[\"%s-%s_mean\" % (var, var)] = sum(l2,[])\n",
    "\n",
    "    data.drop(['Resp','MAP','Temp','HR'], axis = 1, inplace = True)\n",
    "        \n",
    "    return(data, Y_te) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file =\"training_setB/p100017.psv\"  \n",
    "Y_te = code(file)[1]\n",
    "X_te = code(file)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = clf.predict_proba(X_te)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
