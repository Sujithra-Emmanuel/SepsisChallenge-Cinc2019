{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sepsis Challenge\n",
    "\n",
    "Ines Krissaane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import glob\n",
    "from sklearn import linear_model\n",
    "import datetime\n",
    "from sklearn.preprocessing import  StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "#import xgboost as xgb\n",
    "from random import sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import glob\n",
    "import skimage\n",
    "import skimage.transform\n",
    "import skimage.io\n",
    "import PIL\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import imageio\n",
    "import time\n",
    "#import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'sepsis_data_all.csv' does not exist: b'sepsis_data_all.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-25a6ce5866ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sepsis_data_all.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'sepsis_data_all.csv' does not exist: b'sepsis_data_all.csv'"
     ]
    }
   ],
   "source": [
    "X_tr = pd.read_csv('sepsis_data_all.csv')\n",
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X_tr.SepsisLabel, )\n",
    "plt.title('Proportion of line with Sepsis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr.SepsisLabel.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's an **anomaly detection** problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr.SepsisLabel.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = X_tr[X_tr['SepsisLabel'] == 0]\n",
    "anormal = X_tr[X_tr['SepsisLabel'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anormal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_anormal = list(anormal.ID.unique() )\n",
    "list_normal = list(normal.ID.unique() )\n",
    "df = X_tr\n",
    "for i in (list_anormal):\n",
    "    df = df[df.ID != i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = df\n",
    "list_normal = list(normal.ID.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection and missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def na (data):\n",
    "    return(data.isnull().sum().sort_values(ascending=False)/data.isnull().count()).sort_values(ascending=False)\n",
    "\n",
    "na(anormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na(normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important features :\n",
    "    - HR\n",
    "    - Temp\n",
    "    - SBP\n",
    "    - MAP \n",
    "    - DBP \n",
    "    - Resp\n",
    "    - \n",
    "    \n",
    "    - Creatinine \n",
    "    - Bilirubin_direct\n",
    "    - Glucose \n",
    "    - Lactate \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understand the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = pd.read_csv('sepsis_data_setA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curve(var, n):\n",
    "    '''Plot data from n patients who have sepsis at the time indicated by the red line for a specific variable var\n",
    "    var = string for the feature\n",
    "    n = square number for the total number of plots '''\n",
    "    \n",
    "    list_anormal = list(anormal.ID.unique() )\n",
    "    fig, subplot_axes = plt.subplots(int(np.sqrt(n)),int(np.sqrt(n)), squeeze=False, figsize=(16,12))\n",
    "\n",
    "    for it, p in enumerate(list(sample(list_anormal, n))) :\n",
    "        onedf = X_tr[X_tr['ID'] == p]\n",
    "        onedf.index = onedf.ICULOS\n",
    "        ax = subplot_axes[it // int(np.sqrt(n))][it % int(np.sqrt(n))]\n",
    "        ax.plot(X_tr[X_tr['ID'] == p].ICULOS,X_tr[X_tr['ID'] == p][var]);\n",
    "        ax.set_title('Patient number  %i' % p)\n",
    "        ax.axvline(x=np.argmax(onedf['SepsisLabel']), color='red');\n",
    "\n",
    "    plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)\n",
    "    plt.show()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anormal[anormal['ID']==16382]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve('Temp', 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve('HR',25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve('Resp', 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.bar([0,1],[1524294,27916], label=\"\", color='b')\n",
    "plt.legend()\n",
    "plt.xlabel('SepsisLabel')\n",
    "plt.ylabel('Number of measurements')\n",
    "\n",
    "plt.xticks([0,1], ['Normal','Sepsis'])\n",
    "\n",
    "\n",
    "plt.title('An imbalanced dataset')\n",
    "\n",
    "plt.savefig('imbalanced_dataset.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too many NA in some features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove variables with more than 82% of na.\n",
    "X_tr.drop(['EtCO2', 'BaseExcess','HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN', 'Alkalinephos',\n",
    "    'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct' ,'Lactate','Magnesium','Phosphate',\n",
    "    'Potassium', 'Bilirubin_total', 'TroponinI','Hct', 'Hgb','PTT',  'WBC', 'Unnamed: 0','Fibrinogen', 'Platelets',\n",
    "    \"Glucose\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_tr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr.hist(figsize=(10, 10), bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = X_tr.corr()\n",
    "sns.heatmap(corr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unit 1 and Unit 2 are equally proportionnal and no correlation with SepsisLabel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr.drop(['Unit1', \"Unit2\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr.drop([\"ID\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_tr.drop([\"X\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = X_tr.corr()\n",
    "sns.heatmap(corr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the formula MAP = (SBP + 2*DBP) / 3 and the correlation between MAP and DBP, SBP.\n",
    "Let's remove SBP and DBP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr.drop([\"DBP\", \"SBP\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na(X_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values fill in by mean, makes sense because almost all the patients are normal. And you find many missing values only in the variable Temperature Temp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr.fillna(method='bfill', inplace=True)\n",
    "X_tr.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na(X_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only 8 features to explain sepsis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 10))\n",
    "ax0, ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8 = axes.flatten()\n",
    "\n",
    "colors = ['blue', 'red']\n",
    "ax0.hist([X_tr[X_tr.SepsisLabel == 0].Resp,X_tr[X_tr.SepsisLabel == 1].Resp], 5, density=True, histtype='bar', color=colors, label=['No Sepsis', 'Sepsis'])\n",
    "ax0.set_title('Resp')\n",
    "ax0.legend(prop={'size': 10})\n",
    "\n",
    "ax1.hist([X_tr[X_tr.SepsisLabel == 0].Gender,X_tr[X_tr.SepsisLabel == 1].Gender], 5, density=True, histtype='bar', color=colors, label=['No Sepsis', 'Sepsis'])\n",
    "ax1.set_title('Gender')\n",
    "\n",
    "ax2.hist([X_tr[X_tr.SepsisLabel == 0].HR,X_tr[X_tr.SepsisLabel == 1].HR], 5, density=True, histtype='bar', color=colors, label=['No Sepsis', 'Sepsis'])\n",
    "ax2.set_title('HR')\n",
    "\n",
    "ax3.hist([X_tr[X_tr.SepsisLabel == 0].O2Sat,X_tr[X_tr.SepsisLabel == 1].O2Sat], 5, density=True, histtype='bar', color=colors, label=['No Sepsis', 'Sepsis'])\n",
    "ax3.set_title('O2Sat')\n",
    "\n",
    "ax4.hist([X_tr[X_tr.SepsisLabel == 0].MAP,X_tr[X_tr.SepsisLabel == 1].MAP], 5, density=True, histtype='bar', color=colors, label=['No Sepsis', 'Sepsis'])\n",
    "ax4.set_title('MAP')\n",
    "\n",
    "ax5.hist([X_tr[X_tr.SepsisLabel == 0].Temp,X_tr[X_tr.SepsisLabel == 1].Temp], 5, density=True, histtype='bar', color=colors, label=['No Sepsis', 'Sepsis'])\n",
    "ax5.set_title('Temp')\n",
    "\n",
    "ax6.hist([X_tr[X_tr.SepsisLabel == 0].HospAdmTime,X_tr[X_tr.SepsisLabel == 1].HospAdmTime], 5, density=True, histtype='bar', color=colors, label=['No Sepsis', 'Sepsis'])\n",
    "ax6.set_title('HospAdmTime')\n",
    "\n",
    "ax7.hist([X_tr[X_tr.SepsisLabel == 0].ICULOS,X_tr[X_tr.SepsisLabel == 1].ICULOS], 5, density=True, histtype='bar', color=colors, label=['No Sepsis', 'Sepsis'])\n",
    "ax7.set_title('ICULOS')\n",
    "\n",
    "ax8.hist([X_tr[X_tr.SepsisLabel == 0].Age,X_tr[X_tr.SepsisLabel == 1].Age], 5, density=True, histtype='bar', color=colors, label=['No Sepsis', 'Sepsis'])\n",
    "ax8.set_title('Age')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X_tr[X_tr.Age < 20].SepsisLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X_tr[X_tr.Age > 50].SepsisLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X_tr.SepsisLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable Age is correlated to the label sepsis with more than 75% having sepsis and being more than 50 years old. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(X_tr.Gender);\n",
    "plt.title('Proportion of female and male in the dataset');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr.Gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage of sepsis among females\n",
    "sum(X_tr[X_tr.Gender == 0].SepsisLabel) * 100 / 684107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage of sepsis among males\n",
    "sum(X_tr[X_tr.Gender == 1].SepsisLabel) * 100 / 868103"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3916365/\n",
    "    \n",
    "Female gender has been demonstrated to be protective under such conditions, whereas male gender may be deleterious due to a diminished cell-mediated immune response and cardiovascular functions. \n",
    "\n",
    "\n",
    "Gender Female (0) or Male (1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HR** Heart rate (beats per minute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normal resting heart rate for adults over the age of 10 years, including older adults, is between 60 and 100 beats per minute (bpm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X_tr.HR );\n",
    "plt.title('Heart Rate for all measurements');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X_tr[X_tr.HR > 100].SepsisLabel) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O2Sat**  Pulse oximetry (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X_tr.O2Sat);\n",
    "plt.title('Pulse oximetry (%) for all measurements');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal pulse oximeter readings usually range from 95 to 100 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X_tr[X_tr.O2Sat < 95].SepsisLabel) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAP** Mean arterial pressure (mm Hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X_tr.MAP );\n",
    "plt.title('Mean arterial pressure (mm Hg) for all measurements');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It is vital to have a MAP of at least 60 mmHg to provide enough blood to the coronary arteries, kidneys, and brain. The normal MAP range is between 70 and 100 mmHg.\n",
    " A MAP ≥ 65 mmHg is recommended in patients with severe sepsis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X_tr[X_tr.MAP < 70].SepsisLabel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X_tr[X_tr.MAP > 100].SepsisLabel) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time variables : HospAdmTime and ICULOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - HospAdmTime\tHours between hospital admit and ICU admit\n",
    "\n",
    "\n",
    "- ICULOS\tICU length-of-stay (hours since ICU admit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2,  figsize=(10, 5) )\n",
    "ax0, ax1 = axes.flatten()\n",
    "\n",
    "colors = ['blue', 'red']\n",
    "ax0.hist([X_tr[X_tr.SepsisLabel == 0].HospAdmTime,X_tr[X_tr.SepsisLabel == 1].HospAdmTime], 5, density=True, histtype='bar', color=colors, label=['No Sepsis', 'Sepsis'])\n",
    "ax0.set_title('HospAdmTime')\n",
    "ax0.legend(prop={'size': 10})\n",
    "\n",
    "ax1.hist([X_tr[X_tr.SepsisLabel == 0].ICULOS,X_tr[X_tr.SepsisLabel == 1].ICULOS], 5, density=True, histtype='bar', color=colors, label=['No Sepsis', 'Sepsis'])\n",
    "ax1.set_title('ICULOS')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that HospAdmTime does not have a significant impact on SepsisLabel. ICULOS much more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X_tr[X_tr.SepsisLabel == 1].HospAdmTime);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X_tr[X_tr.HospAdmTime < 1].SepsisLabel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X_tr.SepsisLabel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tr = X_tr.SepsisLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('lines_per_patients.csv')\n",
    "plt.hist(data.Nb);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_normal = []\n",
    "for i in (list_normal): \n",
    "    nb_normal.append(int(data[data.ID == i].Nb))\n",
    "\n",
    "nb_anormal = []\n",
    "for i in (list_anormal): \n",
    "    nb_anormal.append(int(data[data.ID == i].Nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(5, 170, 10)\n",
    "plt.hist(nb_normal, bins, label='No Sepsis', color ='blue')\n",
    "plt.hist(nb_anormal, bins,label='Sepsis', color ='red')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Number of rows per patient for both groups')\n",
    "plt.xlabel('Number of rows per patient')\n",
    "plt.ylabel('Number of patients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = pd.read_csv('datasetA_with_new_features.csv')\n",
    "X_tr.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to resume "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that is doing all of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def code(file) :\n",
    "    data = pd.read_csv(file , sep='|')\n",
    "    data.drop(['EtCO2', 'BaseExcess','HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN', 'Alkalinephos',\n",
    "    'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct' , 'Resp','Lactate','Magnesium','Phosphate',\n",
    "    'Potassium', 'Bilirubin_total', 'TroponinI','Hct', 'Hgb','PTT',  'WBC', 'Fibrinogen', 'Platelets',\n",
    "    \"Unit1\", 'Unit2', \"Glucose\",'DBP','SBP'], axis = 1, inplace = True)\n",
    "    data.fillna(method='bfill', inplace=True)\n",
    "    data.fillna(method='ffill', inplace=True)\n",
    "    Y_te = data.SepsisLabel\n",
    "    data.drop(['SepsisLabel'], axis = 1, inplace = True)\n",
    "    col = data.columns\n",
    "    if sum(pd.isna(data['MAP'])) !=0 : \n",
    "        data['MAP'] =  [87] * len(data['MAP'] )\n",
    "    if sum(pd.isna(data['Temp'])) !=0 : \n",
    "        data['Temp'] =  [36.7] * len(data['Temp'] )\n",
    "    if sum(pd.isna(data['HR'])) !=0 : \n",
    "        data['HR'] =  [83.9] * len(data['HR'] )\n",
    "    return(data, Y_te)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection using Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://blog.goodaudience.com/neural-networks-for-anomaly-outliers-detection-a454e3fdaae8\n",
    "- https://medium.com/@ally_20818/anomaly-detection-with-auto-encoders-how-we-used-it-for-cervical-cancer-detection-bdae74cbf05a\n",
    "- https://arxiv.org/pdf/1811.05269.pdf\n",
    "- https://core.ac.uk/download/pdf/81634504.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 101\n",
    "\n",
    "X_train, X_test = train_test_split(X_tr, test_size=0.3, random_state = RANDOM_SEED)\n",
    "\n",
    "X_train = X_train[X_train['SepsisLabel'] == 0]\n",
    "X_train = X_train.drop(['SepsisLabel'], axis=1)\n",
    "\n",
    "y_test  = X_test['SepsisLabel']\n",
    "X_test  = X_test.drop(['SepsisLabel'], axis=1)\n",
    "X_train = X_train.values\n",
    "X_test  = X_test.values\n",
    "print('Training data size   :', X_train.shape)\n",
    "print('Validation data size :', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense,  Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Reshape, Lambda, Flatten, Activation, Dropout\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 64\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"softmax\")(input_layer)\n",
    "encoder = Dense(int(encoding_dim * 8), activation=\"softmax\")(encoder)\n",
    "#encoder = Dense(int(2), activation=\"tanh\")(encoder)\n",
    "#decoder = Dense(int(encoding_dim/ 2), activation='tanh')(encoder)\n",
    "decoder = Dense(int(encoding_dim), activation='softmax')(encoder)\n",
    "decoder = Dense(input_dim, activation='softmax')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 100\n",
    "batch_size = 50\n",
    "autoencoder.compile(optimizer='adam', loss='mse' )\n",
    "\n",
    "t_ini = datetime.datetime.now()\n",
    "history = autoencoder.fit(X_train_scaled, X_train_scaled,\n",
    "                        epochs=nb_epoch,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        validation_split=0.2,\n",
    "                        verbose=0\n",
    "                        )\n",
    "\n",
    "t_fin = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('Time to run the model: {} Sec.'.format((t_fin - t_ini).total_seconds()))\n",
    "df_history = pd.DataFrame(history.history)\n",
    "1476.410182 Sec.  \n",
    "for 8/6/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Time to run the model: {} Sec.'.format((t_fin - t_ini).total_seconds()))\n",
    "df_history = pd.DataFrame(history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,101), df_history['loss']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(X_test_scaled)\n",
    "mse = np.mean(np.power(X_test_scaled - predictions, 2), axis=1)\n",
    "df_error = pd.DataFrame({'reconstruction_error': mse, 'Label': y_test}, index=y_test.index)\n",
    "df_error.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,len(df_error['reconstruction_error'])), df_error['reconstruction_error']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_error['reconstruction_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = df_error.index[df_error.reconstruction_error > 0.2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr[X_tr.SepsisLabel == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b =set(list(y_test[y_test == 1].index))\n",
    "len([i for i, item in enumerate(outliers) if item in b])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = autoencoder.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "autoencoder.save_weights(\"model.h5\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normality of the reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "k2, p = stats.normaltest(df_error['reconstruction_error'])\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pylab\n",
    "sm.qqplot(df_error['reconstruction_error'], loc = 4, scale = 3, line='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = df_error['reconstruction_error']\n",
    "arr.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = df_error['reconstruction_error']\n",
    "final_list = [ x for x in arr if (x > arr.mean() - 2 * arr.std())]\n",
    "final_list = [x for x in final_list if (x < arr.mean() + 2 * arr.std())]\n",
    "len(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code(file) :\n",
    "    data = pd.read_csv(file , sep='|')\n",
    "    data.drop(['EtCO2', 'BaseExcess','HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN', 'Alkalinephos',\n",
    "    'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct' , 'Resp','Lactate','Magnesium','Phosphate',\n",
    "    'Potassium', 'Bilirubin_total', 'TroponinI','Hct', 'Hgb','PTT',  'WBC', 'Fibrinogen', 'Platelets',\n",
    "    \"Unit1\", 'Unit2', \"Glucose\",'DBP','SBP'], axis = 1, inplace = True)\n",
    "    data.fillna(method='bfill', inplace=True)\n",
    "    data.fillna(method='ffill', inplace=True)\n",
    "    Y_te = data.SepsisLabel\n",
    "    data.drop(['SepsisLabel'], axis = 1, inplace = True)\n",
    "    col = data.columns\n",
    "    if sum(pd.isna(data['MAP'])) !=0 : \n",
    "        data['MAP'] =  [87] * len(data['MAP'] )\n",
    "    if sum(pd.isna(data['Temp'])) !=0 : \n",
    "        data['Temp'] =  [36.7] * len(data['Temp'] )\n",
    "    if sum(pd.isna(data['HR'])) !=0 : \n",
    "        data['HR'] =  [83.9] * len(data['HR'] )\n",
    "    return(data, Y_te)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_challenge_data(file):\n",
    "    with open(file, 'r') as f:\n",
    "        header = f.readline().strip()\n",
    "        column_names = header.split('|')\n",
    "        data = np.loadtxt(f, delimiter='|')\n",
    "\n",
    "    # Ignore SepsisLabel column if present.\n",
    "    if column_names[-1] == 'SepsisLabel':\n",
    "        column_names = column_names[:-1]\n",
    "        data = data[:, :-1]\n",
    "\n",
    "    return pd.DataFrame(data, columns = column_names )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_challenge_data(\"training_setB/p119959.psv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = code(\"training_setB/p119959.psv\")[0]\n",
    "r = code(\"training_setB/p119959.psv\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "d = scaler.fit_transform(d)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = loaded_model.predict(d)\n",
    "mse = np.mean(np.power(d - probabilities , 2), axis=1)\n",
    "df_error = pd.DataFrame({'reconstruction_error': mse, 'Label': r}, index=r.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,len(df_error['reconstruction_error'])+1), df_error['reconstruction_error']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = df_error.index[df_error.reconstruction_error > 0.18].tolist()\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All datasetB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auc(labels, predictions):\n",
    "    # Check inputs for errors.\n",
    "\n",
    "    # Find prediction thresholds.\n",
    "    thresholds = np.unique(predictions)[::-1]\n",
    "    if thresholds[0] != 1:\n",
    "        thresholds = np.concatenate((np.array([1]), thresholds))\n",
    "\n",
    "    if thresholds[-1] != 0:\n",
    "        thresholds = np.concatenate((thresholds, np.array([0])))\n",
    "    m = len(thresholds)\n",
    "\n",
    "    # Populate contingency table across prediction thresholds.\n",
    "    tp = np.zeros(m)\n",
    "    fp = np.zeros(m)\n",
    "    fn = np.zeros(m)\n",
    "    tn = np.zeros(m)\n",
    "\n",
    "    # Find indices that sort predicted probabilities from largest to smallest.\n",
    "    idx = np.argsort(predictions)[::-1]\n",
    "\n",
    "    i = 0\n",
    "    for j in range(m):\n",
    "        # Initialize contingency table for j-th prediction threshold.\n",
    "        if j == 0:\n",
    "            tp[j] = 0\n",
    "            fp[j] = 0\n",
    "            fn[j] = np.sum(labels == 1)\n",
    "            tn[j] = np.sum(labels == 0)\n",
    "        else:\n",
    "            tp[j] = tp[j - 1]\n",
    "            fp[j] = fp[j - 1]\n",
    "            fn[j] = fn[j - 1]\n",
    "            tn[j] = tn[j - 1]\n",
    "\n",
    "        # Update contingency table for i-th largest prediction probability.\n",
    "        while i < n and predictions[idx[i]] >= thresholds[j]:\n",
    "            if labels[idx[i]]:\n",
    "                tp[j] += 1\n",
    "                fn[j] -= 1\n",
    "            else:\n",
    "                fp[j] += 1\n",
    "                tn[j] -= 1\n",
    "            i += 1\n",
    "\n",
    "    # Summarize contingency table.\n",
    "    tpr = np.zeros(m)\n",
    "    tnr = np.zeros(m)\n",
    "    ppv = np.zeros(m)\n",
    "    npv = np.zeros(m)\n",
    "\n",
    "    for j in range(m):\n",
    "        if tp[j] + fn[j]:\n",
    "            tpr[j] = tp[j] / (tp[j] + fn[j])\n",
    "        else:\n",
    "            tpr[j] = 1\n",
    "        if fp[j] + tn[j]:\n",
    "            tnr[j] = tn[j] / (fp[j] + tn[j])\n",
    "        else:\n",
    "            tnr[j] = 1\n",
    "        if tp[j] + fp[j]:\n",
    "            ppv[j] = tp[j] / (tp[j] + fp[j])\n",
    "        else:\n",
    "            ppv[j] = 1\n",
    "        if fn[j] + tn[j]:\n",
    "            npv[j] = tn[j] / (fn[j] + tn[j])\n",
    "        else:\n",
    "            npv[j] = 1\n",
    "\n",
    "    # Compute AUROC as the area under a piecewise linear function of TPR /\n",
    "    # sensitivity (x-axis) and TNR / specificity (y-axis) and AUPRC as the area\n",
    "    # under a piecewise constant of TPR / recall (x-axis) and PPV / precision\n",
    "    # (y-axis).\n",
    "    auroc = 0\n",
    "    auprc = 0\n",
    "    for j in range(m-1):\n",
    "        auroc += 0.5 * (tpr[j + 1] - tpr[j]) * (tnr[j + 1] + tnr[j])\n",
    "        auprc += (tpr[j + 1] - tpr[j]) * ppv[j + 1]\n",
    "\n",
    "    return auroc, auprc\n",
    "\n",
    "# The compute_accuracy_f_measure function computes the accuracy and F-measure\n",
    "# for a patient.\n",
    "#\n",
    "# Inputs:\n",
    "#   'labels' is a binary vector, where labels[i] == 0 if the patient is not\n",
    "#   labeled as septic at time i and labels[i] == 1 if the patient is labeled as\n",
    "#   septic at time i.\n",
    "#\n",
    "#   'predictions' is a binary vector, where predictions[i] == 0 if the patient\n",
    "#   is not predicted to be septic at time i and predictions[i] == 1 if the\n",
    "#   patient is predicted to be septic at time i.  Note that there must be a\n",
    "#   prediction for every label, i.e, len(labels) == len(predictions).\n",
    "#\n",
    "# Output:\n",
    "#   'accuracy' is a scalar that gives the accuracy of the classifier using its\n",
    "#   binarized predictions.\n",
    "#\n",
    "#   'f_measure' is a scalar that gives the F-measure of the classifier using its\n",
    "#   binarized predictions.\n",
    "#\n",
    "# Example:\n",
    "#   In [1]: labels = [0, 0, 0, 0, 1, 1]\n",
    "#   In [2]: predictions = [0, 0, 1, 1, 1, 1]\n",
    "#   In [3]: accuracy, f_measure = compute_prediction_utility(labels, predictions)\n",
    "#   In [4]: accuracy\n",
    "#   Out[4]: 0.666666666667\n",
    "#   In [5]: f_measure\n",
    "#   Out[5]: 0.666666666667\n",
    "\n",
    "def compute_accuracy_f_measure(labels, predictions):\n",
    "    # Check inputs for errors.\n",
    "    if len(predictions) != len(labels):\n",
    "        raise Exception('Numbers of predictions and labels must be the same.')\n",
    "\n",
    "    n = len(labels)\n",
    "    for i in range(n):\n",
    "        if not labels[i] in (0, 1):\n",
    "            raise Exception('Labels must satisfy label == 0 or label == 1.')\n",
    "\n",
    "    for i in range(n):\n",
    "        if not predictions[i] in (0, 1):\n",
    "            raise Exception('Predictions must satisfy prediction == 0 or prediction == 1.')\n",
    "\n",
    "    # Populate contingency table.\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        if labels[i] and predictions[i]:\n",
    "            tp += 1\n",
    "        elif labels[i] and not predictions[i]:\n",
    "            fp += 1\n",
    "        elif not labels[i] and predictions[i]:\n",
    "            fn += 1\n",
    "        elif not labels[i] and not predictions[i]:\n",
    "            tn += 1\n",
    "\n",
    "    # Summarize contingency table.\n",
    "    if tp + fp + fn + tn:\n",
    "        accuracy = float(tp + tn) / float(tp + fp + fn + tn)\n",
    "    else:\n",
    "        accuracy = 1.0\n",
    "\n",
    "    if 2 * tp + fp + fn:\n",
    "        f_measure = float(2 * tp) / float(2 * tp + fp + fn)\n",
    "    else:\n",
    "        f_measure = 1.0\n",
    "\n",
    "    return accuracy, f_measure\n",
    "\n",
    "# The compute_prediction_utility function computes the total time-dependent\n",
    "# utility for a patient.\n",
    "#\n",
    "# Inputs:\n",
    "#   'labels' is a binary vector, where labels[i] == 0 if the patient is not\n",
    "#   labeled as septic at time i and labels[i] == 1 if the patient is labeled as\n",
    "#   septic at time i.\n",
    "#\n",
    "#   'predictions' is a binary vector, where predictions[i] == 0 if the patient\n",
    "#   is not predicted to be septic at time i and predictions[i] == 1 if the\n",
    "#   patient is predicted to be septic at time i.  Note that there must be a\n",
    "#   prediction for every label, i.e, len(labels) == len(predictions).\n",
    "#\n",
    "# Output:\n",
    "#   'utility' is a scalar that gives the total time-dependent utility of the\n",
    "#   classifier using its binarized predictions.\n",
    "#\n",
    "# Example:\n",
    "#   In [1]: labels = [0 0 0 0 1 1]\n",
    "#   In [2]: predictions = [0 0 1 1 1 1]\n",
    "#   In [3]: utility = compute_prediction_utility(labels, predictions)\n",
    "#   In [4]: utility\n",
    "#   Out[4]: 0.444444444444\n",
    "\n",
    "def compute_prediction_utility(labels, predictions, dt_early=-12, dt_optimal=-6, dt_late=3.0, max_u_tp=1, min_u_fn=-2, u_fp=-0.05, u_tn=0):\n",
    "    # Check inputs for errors.\n",
    "    if len(predictions) != len(labels):\n",
    "        raise Exception('Numbers of predictions and labels must be the same.')\n",
    "\n",
    "    n = len(labels)\n",
    "    for i in range(n):\n",
    "        if not labels[i] in (0, 1):\n",
    "            raise Exception('Labels must satisfy label == 0 or label == 1.')\n",
    "\n",
    "    for i in range(n):\n",
    "        if not predictions[i] in (0, 1):\n",
    "            raise Exception('Predictions must satisfy prediction == 0 or prediction == 1.')\n",
    "\n",
    "    if dt_early >= dt_optimal:\n",
    "        raise Exception('The earliest beneficial time for predictions must be before the optimal time.')\n",
    "\n",
    "    if dt_optimal >= dt_late:\n",
    "        raise Exception('The optimal time for predictions must be before the latest beneficial time.')\n",
    "\n",
    "    # Does the patient eventually have sepsis?\n",
    "    if any(labels):\n",
    "        is_septic = True\n",
    "        t_sepsis = min(i for i, label in enumerate(labels) if label) - dt_optimal\n",
    "    else:\n",
    "        is_septic = False\n",
    "        t_sepsis = float('inf')\n",
    "\n",
    "    # Define slopes and intercept points for affine utility functions of the\n",
    "    # form u = m * t + b.\n",
    "    m_1 = float(max_u_tp) / float(dt_optimal - dt_early)\n",
    "    b_1 = -m_1 * dt_early\n",
    "    m_2 = float(-max_u_tp) / float(dt_late - dt_optimal)\n",
    "    b_2 = -m_2 * dt_late\n",
    "    m_3 = float(min_u_fn) / float(dt_late - dt_optimal)\n",
    "    b_3 = -m_3 * dt_optimal\n",
    "\n",
    "    # Compare predicted and true conditions.\n",
    "    u = np.zeros(n)\n",
    "    for t in range(n):\n",
    "        if t <= t_sepsis + dt_late:\n",
    "            # TP\n",
    "            if is_septic and predictions[t]:\n",
    "                if t <= t_sepsis + dt_optimal:\n",
    "                    u[t] = max(m_1 * (t - t_sepsis) + b_1, u_fp)\n",
    "                elif t <= t_sepsis + dt_late:\n",
    "                    u[t] = m_2 * (t - t_sepsis) + b_2\n",
    "            # FN\n",
    "            elif is_septic and not predictions[t]:\n",
    "                if t <= t_sepsis + dt_optimal:\n",
    "                    u[t] = 0\n",
    "                elif t <= t_sepsis + dt_late:\n",
    "                    u[t] = m_3 * (t - t_sepsis) + b_3\n",
    "            # FP\n",
    "            elif not is_septic and predictions[t]:\n",
    "                u[t] = u_fp\n",
    "            # TN\n",
    "            elif not is_septic and not predictions[t]:\n",
    "                u[t] = u_tn\n",
    "\n",
    "    # Find total utility for patient.\n",
    "    return np.sum(u)\n",
    "\n",
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser(description = 'Evaluate classifiers for cohort.')\n",
    "    parser.add_argument('-l', '--labels_directory',      type=str, required=True,  help='Labels directory')\n",
    "    parser.add_argument('-p', '--predictions_directory', type=str, required=True,  help='Predictions directory')\n",
    "    parser.add_argument('-o', '--output_file',           type=str, required=False, help='Output filename')\n",
    "    return parser\n",
    "\n",
    "def run(args):\n",
    "    auroc, auprc, accuracy, f_measure, utility = compute_scores_2019(args.labels_directory, args.predictions_directory)\n",
    "\n",
    "    output_string = 'AUROC|AUPRC|Accuracy|F-measure|Utility\\n{}|{}|{}|{}|{}'.format(auroc, auprc, accuracy, f_measure, utility)\n",
    "\n",
    "    if args.output_file:\n",
    "        with open(args.output_file, 'w') as f:\n",
    "            f.write(output_string)\n",
    "    else:\n",
    "        print(output_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility = []\n",
    "optimal = []\n",
    "acc=[]\n",
    "nopred=[]\n",
    "\n",
    "for file in glob.glob(\"training_setB/*.psv\")[1:3]:  \n",
    "    Y_te = code(file)[1]\n",
    "    X_te = code(file)[0]\n",
    "    \n",
    "   \n",
    "    scaler = MinMaxScaler()\n",
    "    X_te = scaler.fit_transform(X_te)\n",
    "    \n",
    "    probabilities = loaded_model.predict(X_te)\n",
    "    \n",
    "    mse = np.mean(np.power(X_te - probabilities , 2), axis=1)\n",
    "    df_error = pd.DataFrame({'reconstruction_error': mse, 'Label': Y_te}, index=Y_te.index)\n",
    "    outliers = df_error.index[df_error.reconstruction_error > 0.18].tolist()\n",
    "    \n",
    "    predictions = []\n",
    "    for i in range(0, len(df_error) ):\n",
    "        if df_error.reconstruction_error[i] > 0.18 :\n",
    "            predictions.append(1)\n",
    "        else :\n",
    "            predictions.append(0)\n",
    "\n",
    "\n",
    "    labels = df_error.Label\n",
    "   \n",
    "    accuracy, f_measure = compute_accuracy_f_measure(labels, predictions)\n",
    "    acc.append(accuracy)\n",
    "    utility.append(compute_prediction_utility(labels, predictions))\n",
    "    optimal.append(compute_prediction_utility(labels, labels))\n",
    "    \n",
    "    fake = []\n",
    "    for i in labels :\n",
    "        fake.append(1-i)\n",
    "    nopred.append(compute_prediction_utility(labels, fake))\n",
    "    #nopred.append(compute_prediction_utility(labels, fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(optimal);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(utility) - sum(nopred) )/(sum(optimal) - sum(nopred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(utility);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_n = pd.DataFrame(X_test_scaled, index= y_test.index)\n",
    "                      \n",
    "def compute_error_per_dim(point):\n",
    "    initial_pt = np.array(data_n.loc[point,:]).reshape(1,9)\n",
    "    reconstrcuted_pt = autoencoder.predict(initial_pt)\n",
    "    \n",
    "    return(abs(np.array(initial_pt  - reconstrcuted_pt)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_error_per_dim(1342254)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_error_per_dim(1126533)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_error_per_dim(944174)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_error_per_dim(1475332)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_error_per_dim(993319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_error_per_dim(715894)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_error_per_dim( 607628)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = pd.read_csv('sepsis_data_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr.drop(['EtCO2', 'BaseExcess','HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN', 'Alkalinephos',\n",
    "    'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct' , 'Resp','Lactate','Magnesium','Phosphate',\n",
    "    'Potassium', 'Bilirubin_total', 'TroponinI','Hct', 'Hgb','PTT',  'WBC', 'Fibrinogen', 'Platelets',\n",
    "    \"Unit1\", 'Unit2', \"Glucose\",'HospAdmTime','Unnamed: 0', 'ID','DBP','X','Temp','Age','Gender'], axis = 1, inplace = True)\n",
    "X_tr.fillna(method='bfill', inplace=True)\n",
    "X_tr.fillna(method='ffill', inplace=True)\n",
    "\n",
    "Y_tr = X_tr.SepsisLabel\n",
    "X_tr.drop(['SepsisLabel'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_tr.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tr,Y_tr,test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth': 11,\n",
    "    'min_child_weight': 5,\n",
    "    'eta':.01,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'objective':'binary:logistic',\n",
    "    'eval_metric': 'rmse'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'rmse'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(3,12)\n",
    "    for min_child_weight in range(1,7)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mae = float(\"Inf\")\n",
    "\n",
    "\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best MAE\n",
    "    mean_mae = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 11\n",
    "params['min_child_weight'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = 1.0\n",
    "params['colsample_bytree'] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# This can take some time…\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "    # Run and time CV\n",
    "    %time cv_results = xgb.cv(params,dtrain,num_boost_round=num_boost_round,seed=42,nfold=5,metrics=['mae'],early_stopping_rounds=10)\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eta'] = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = model.best_iteration + 1\n",
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(best_model.predict(dtest), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save_model(\"my_xgboost_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = xgb.Booster()\n",
    "loaded_model.load_model(\"my_xgboost_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = linear_model.Lasso(alpha=0)\n",
    "model.fit(X_tr,Y_tr)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "model.fit(X_tr,Y_tr)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  RandomForestRegressor(n_estimators=200)\n",
    "model.fit(X_tr,Y_tr)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = KNeighborsClassifier(algorithm= 'ball_tree', n_neighbors= 6,p= 1, weights= 'distance').fit( X_tr,Y_tr)\n",
    "model.fit(X_tr,Y_tr)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_tr = pd.read_csv('sepsis_data.csv')\n",
    "X_tr[X_tr.MAP > 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Y_te =  code('training\\p02705.psv')[1]\n",
    "X_te = code('training\\p02705.psv')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(Y_tr == 0)/len(Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "utility = []\n",
    "optimal = []\n",
    "nopred=[]\n",
    "acc=[]\n",
    "number_un = []\n",
    "for file in glob.glob(\"training_setB/*.psv\")[10000:20000]:  #[3200:5000]\n",
    "    Y_te =  code(file)[1]\n",
    "    X_te = code(file)[0]\n",
    "    number_un.append(sum(Y_te))\n",
    "   # print(file)\n",
    "   # 1 probabilities  = model.predict(X_te)\n",
    "    \n",
    "    #2 \n",
    "    dtest = xgb.DMatrix(X_te, label= Y_te)\n",
    "    probabilities = best_model.predict(dtest)\n",
    "\n",
    "\n",
    "    #probabilities = model.predict_proba(X_te)[:,1]\n",
    "    #predictions = model.predict(X_te)\n",
    "    for counter, value in enumerate(probabilities):\n",
    "        if value > 0.1:\n",
    "            if counter < (len(probabilities)-3) :\n",
    "                probabilities[counter+1] = 1\n",
    "                probabilities[counter+2] = 1\n",
    "                probabilities[counter+3] = 1\n",
    "    \n",
    "    predictions = [] \n",
    "    for i in range (len(probabilities)):\n",
    "        if probabilities[i] < 0.5 :   # 1 0.35\n",
    "            predictions.append(0)\n",
    "        else :\n",
    "            predictions.append(1)\n",
    "\n",
    "    labels = Y_te\n",
    "    fake = []\n",
    "    for i in labels :\n",
    "        fake.append(1-i)\n",
    "    \n",
    "        \n",
    "    n = len(labels)\n",
    "    \n",
    "    cohort_labels        = []\n",
    "    cohort_predictions   = []\n",
    "    cohort_probabilities = []\n",
    "\n",
    "    cohort_labels.append(labels)\n",
    "    cohort_predictions.append(predictions)\n",
    "    cohort_probabilities.append(probabilities)\n",
    "    labels        = np.concatenate(cohort_labels)\n",
    "    predictions   = np.concatenate(cohort_predictions)\n",
    "    probabilities = np.concatenate(cohort_probabilities)\n",
    "\n",
    "    auroc, auprc        = compute_auc(labels, probabilities)\n",
    "    accuracy, f_measure = compute_accuracy_f_measure(labels, predictions)\n",
    "    acc.append(accuracy)\n",
    "    utility.append(compute_prediction_utility(labels, predictions))\n",
    "    optimal.append(compute_prediction_utility(labels, labels))\n",
    "    nopred.append(compute_prediction_utility(labels, fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(utility) - sum(nopred) )/(sum(optimal) - sum(nopred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(utility) - sum(nopred) )/(sum(optimal) - sum(nopred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(utility) - sum(nopred) )/(sum(optimal) - sum(nopred)) #0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(utility) - sum(nopred) )/(sum(optimal) - sum(nopred)) #0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(utility) - sum(nopred) )/(sum(optimal) - sum(nopred)) #0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(utility) - sum(nopred) )/(sum(optimal) - sum(nopred)) #0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(utility) - sum(nopred) )/(sum(optimal) - sum(nopred)) #0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(utility) - sum(nopred) )/(sum(optimal) - sum(nopred)) #0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(utility) - sum(nopred) )/(sum(optimal) - sum(nopred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(utility) - sum(nopred) )/(sum(optimal) - sum(nopred)) #rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(utility) - sum(nopred) )/(sum(optimal) - sum(nopred))  # xgboost 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(utility) - sum(nopred) )/(sum(optimal) - sum(nopred))  # xgboost 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(utility) - sum(nopred) )/(sum(optimal) - sum(nopred))  # xgboost 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(utility) - sum(nopred) )/(sum(optimal) - sum(nopred))  # xgboost 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(utility) - sum(nopred) )/(sum(optimal) - sum(nopred)) #xgboost 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sum(acc)/len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sum(acc)/len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(number_un);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(optimal);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(optimal);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(nopred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(nopred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(utility);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(utility);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "s=0\n",
    "for i in optimal : \n",
    "    if i>0 :\n",
    "        s +=1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "s=0\n",
    "for i in utility : \n",
    "    if i>0 :\n",
    "        s +=1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bad = []\n",
    "for i in utility:\n",
    "    if i < 0:\n",
    "        bad.append(i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "X_te = code('training\\p00356.psv')[0]\n",
    "Y_te =  code('training\\p00356.psv')[1]\n",
    "probabilities  = model.predict(X_te)\n",
    "\n",
    "labels = Y_te"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for counter, value in enumerate(utility):\n",
    "    if value < 0 :\n",
    "        print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## xgbabsoost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_tr, label=Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:linear',\n",
    "    'eval_metric' : 'mae'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = data.SepsisLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['SepsisLabel'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr,X_te,Y_tr,Y_te = train_test_split(data, Y_train, random_state =24 , test_size = 0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix du premier modèle qui semble évident : régréssion linéaire\n",
    "model = LinearRegression()\n",
    "model.fit(X_tr,Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On test sur le jeu de validation\n",
    "predictions = model.predict(X_te) #On prédit le jeu de validation\n",
    "print ('Erreur de la régréssion linéaire sur le jeu de validation : ', rmse(predictions,Y_te) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(Y_te,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = RandomForestRegressor(random_state = 1234) \n",
    "model.fit(X_tr,Y_tr) # On fait apprendre sur le jeu d'apprentissage entier + cible\n",
    "probabilities  = model.predict(X_te)\n",
    "print ( 'Erreur d\\'une random forest non optimisée sur le jeu de test : ', rmse(probabilities ,Y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state = 1234) \n",
    "model = XGBRegressor(n_estimators=1000) \n",
    "model.fit(X_tr,Y_tr) # On fait apprendre sur le jeu d'apprentissage entier + cible\n",
    "probabilities = model.predict(X_te)\n",
    "print('Erreur d\\'un ExtremBoosting non optimisé sur le jeu de test : ', rmse(probabilities,Y_te) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier().fit( X_tr,Y_tr)\n",
    "probabilities = model.predict_proba(X_te)[:,1]\n",
    "predictions = model.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(algorithm= 'ball_tree', n_neighbors= 30,p= 1, weights= 'distance').fit( X_tr,Y_tr)\n",
    "probabilities = model.predict_proba(X_te)[:,1]\n",
    "predictions = model.predict(X_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation(clfs):\n",
    "    for clf in clfs:\n",
    "        clfs[clf]['score'] = cross_val_score(clfs[clf]['clf'], X_tr,Y_tr, cv=5,scoring='roc_auc')\n",
    "        print(clfs[clf]['name'] + \": %0.4f (+/- %0.4f)\" % (clfs[clf]['score'].mean(), clfs[clf]['score'].std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clfs = {}\n",
    "\n",
    "clfs['ada'] = {'clf': AdaBoostClassifier(), 'name': 'AdaBoostClassifier'}\n",
    "clfs['gbc'] = {'clf': GradientBoostingClassifier(), 'name': 'GradientBoostingClassifier'}\n",
    "clfs['rf'] = {'clf': RandomForestClassifier( n_jobs=-1), 'name':'RandomForest'}\n",
    "clfs['tree'] = {'clf': DecisionTreeClassifier(), 'name':'DecisionTreeClassifier'}\n",
    "#clfs['svc'] = {'clf': SVC(), 'name': 'SupportVectorClassifier'}\n",
    "clfs['knn'] = {'clf': KNeighborsClassifier(), 'name': 'KNeighborsClassifier'}\n",
    "\n",
    "\n",
    "Evaluation(clfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = {}\n",
    "\n",
    "reg['LR'] = {'reg' : LinearRegression(), 'name' : 'LinearRegression'}\n",
    "reg['RF'] = {'reg' : RandomForestRegressor() , 'name' : 'RandomForestRegressor'}\n",
    "reg['XGB'] = {'reg' : XGBRegressor()  , 'name' : 'XGBRegressor'}\n",
    "\n",
    "\n",
    "def Evaluation(clfs):\n",
    "    for clf in clfs:\n",
    "        clfs[clf]['score'] = cross_val_score(clfs[clf]['reg'], X_tr,Y_tr, cv=5, scoring = 'roc_auc')\n",
    "        print(clfs[clf]['name'] + \": %0.4f (+/- %0.4f)\" % (clfs[clf]['score'].mean(), clfs[clf]['score'].std()*2))\n",
    "\n",
    "        \n",
    "Evaluation(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier().fit( X_tr,Y_tr)\n",
    "probabilities = model.predict_proba(X_te)[:,1]\n",
    "print ('Performance du modèle :', roc_auc_score(Y_te, probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "#Attention, cela peut être long !\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "params = {\n",
    "    'n_neighbors' : [5,10,15],\n",
    "    'weights' : ['uniform' , 'distance'],\n",
    "    'p': [1, 2],\n",
    "    'algorithm' : ['auto']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(model,param_grid=params,cv=3,scoring = 'roc_auc',n_jobs=-1,verbose = 1)\n",
    "grid.fit(X_tr,Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Résultat de la grid search :', grid.best_score_, grid.best_params_)\n",
    "\n",
    "##On peut récupérer le meilleur modèle : \n",
    "best = grid.best_estimator_\n",
    "\n",
    "print ('Performance du modèle optimisé :', roc_auc_score(Y_te,best.predict_proba(X_te)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor() \n",
    "\n",
    "params = {\n",
    "    'n_estimators' : [100],\n",
    "    'criterion' : ['mse'],\n",
    "    'max_features' :['auto','sqrt','log2']\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "grid = GridSearchCV(model,param_grid=params,cv=3,scoring = 'roc_auc',n_jobs=-1,verbose = 1)\n",
    "grid.fit(X_tr,Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Résultat de la grid search :', grid.best_score_, grid.best_params_)\n",
    "\n",
    "##On peut récupérer le meilleur modèle : \n",
    "best = grid.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "probabilities  = best.predict(X_te)\n",
    "print ( 'Erreur d\\'une random forest non optimisée sur le jeu de test : ', rmse(probabilities ,Y_te))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
